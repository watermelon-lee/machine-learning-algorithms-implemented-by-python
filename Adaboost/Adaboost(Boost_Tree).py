"""
@File    : Adaboost(Boost_Tree).py
@Time    : 2019-12-04 15:00
@Author  : Lee
@Software: PyCharm
@Email: leehaoran@pku.edu.cn
"""


# mnist_train:60000
# mnist_test:10000


# å®é™…è®­ç»ƒä½¿ç”¨ 1000
# å®é™…é¢„æµ‹ä½¿ç”¨ 200
# acc: 0.98
# time: 285s



import pandas as pd
import numpy as np
import time


def loadData(fileName):
    #ä»æ–‡ä»¶ä¸­è¯»å–æ•°æ®
    data=pd.read_csv(fileName,header=None)
    # å°†æ•°æ®ä»dataframeè½¬åŒ–ä¸ºndarray
    data=data.values
    #æ•°æ®ç¬¬ä¸€è¡Œä¸ºåˆ†ç±»ç»“æœ
    y_label=data[:,0]
    x_label=data[:,1:]

    #æ•°æ®äºŒå€¼åŒ–ï¼Œè¿”å›æ•°æ®
    #å› ä¸ºxiçš„å–å€¼èŒƒå›´ä¸º0-255ï¼Œé‚£ä¹ˆåˆ’åˆ†ç‚¹å¤ªå¤šäº†ï¼Œæˆ‘ä»¬è¿›è¡ŒäºŒå€¼åŒ–
    # äºŒå€¼åŒ–ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨-0.5,0.5,1.5ä¸‰ä¸ªç‚¹å³å¯
    x_label[x_label<128]=0
    x_label[x_label>=128]=1

    # ä»¥5ä½œä¸ºåˆ†ç•Œä¸‹æ•ˆæœä¸å¥½ï¼Œæ­£ç¡®ç‡åœ¨80å·¦å³ã€‚ä¹Ÿæ˜æ˜¾å¼ºäºäº†50%
    # y_label[y_label<5]=-1
    # y_label[y_label>=5]=1

    # ä»¥0ä½œä¸ºåˆ†ç±»ã€‚0è®¾ç½®ä¸º-1ï¼Œå…¶ä»–è®¾ç½®ä¸º1
    y_label[y_label ==0 ] = -1
    y_label[y_label>=1]=1

    # np.ndarray
    return x_label,y_label


def cal_Gx_e(X,Y,div,rule,D,feature):
    '''
    ç”¨äºè®¡ç®—åœ¨è¯¥ç‰¹å¾ä¸‹ï¼Œä½¿ç”¨æ¡ä»¶ä¸ºruleï¼Œæ ·æœ¬æƒé‡åˆ†å¸ƒä¸ºDï¼Œåˆ’åˆ†ç‚¹ä¸ºdivï¼Œè¿”å›åˆ’åˆ†ç»“æœå’Œè¯¯å·®ç‡
    :param:X æ ·æœ¬
    :param:Y æ ‡ç­¾
    :param div: åˆ’åˆ†ç‚¹
    :param rule: åˆ’åˆ†è§„åˆ™ï¼Œå¤§äºdivä¸º1è¿˜æ˜¯0
    :param D: æ ·æœ¬æƒé‡åˆ†å¸ƒ
    :param feature: æ ·æœ¬çš„çš„å‡ ä¸ªç‰¹å¾ï¼ˆæ€»å…±æœ‰784ï¼ˆ28*28ï¼‰ä¸ªï¼‰
    :return: Gxï¼Œe
    '''

    x=X[:,feature] #æ‹¿å‡ºæˆ‘ä»¬é€‰æ‹©çš„ä¸€åˆ—

    # ruleåˆ†ä¸ºLessIsOneï¼šå³å°äºåˆ’åˆ†ç‚¹ä¸º1ï¼Œå¤§äºä¸º0ã€‚BiggerIsOneï¼šå¤§äºåˆ’åˆ†ç‚¹ä¸º1ï¼Œå°äºä¸º-1
    Gx=[]
    e=0
    if rule=='LessIsOne':
        L,B=1,-1
    else:
        L,B=-1,1
    for i in range(len(x)):
        #ä¾æ®æ ·æœ¬ç‚¹åœ¨è¯¥åˆ’åˆ†ç‚¹çš„å·¦å³ï¼Œé¢„æµ‹GX
        if x[i]>div: #å³ä¾§ï¼Œé¢„æµ‹ä¸ºBï¼Œå³å¤§äºåˆ’åˆ†ç‚¹
            Gxi=B
            Gx.append(Gxi)
        else:
            Gxi=L
            Gx.append(Gxi)
        if Gxi!=Y[i]:
            e+=D[i] #é”™è¯¯åˆ†ç±»ï¼Œ æ ¹æ®å…¬å¼8.1ç´¯åŠ è®¡ç®—e

    # ä¹‹åè¦è¿›è¡Œè®¡ç®—ä¸‹ä¸€è½®çš„æƒå€¼ï¼Œä½¿ç”¨np.arrayæ–¹ä¾¿äºä½¿ç”¨å‘é‡çš„æ–¹å¼ä¸€æ¬¡è®¡ç®—æ‰€æœ‰æƒå€¼
    return np.array(Gx),e

def create_single_boosting_tree(X,Y,D):
    '''
    åˆ›å»ºå•å±‚æå‡æ ‘ï¼Œæ‰¾åˆ°è¯¯åˆ†ç±»ç‡æœ€å°çš„åˆ’åˆ†æ–¹å¼
    :param D: å‰ä¸€è½®è®­ç»ƒæ•°æ®æƒå€¼åˆ†å¸ƒ
    :return: single_boosting_tree,å•å±‚æå‡æ ‘
    '''

    single_boosting_tree={}

    m,n=X.shape

    single_boosting_tree['e']=1 #åˆå§‹åŒ–é”™è¯¯ç‡ 0<=e<=1
    for i in range(n): #éå†æ¯ä¸€ä¸ªç‰¹å¾ï¼Œå¯»æ‰¾æœ€å¥½çš„åˆ’åˆ†ã€‚
        for rule in ['LessIsOne','BiggerIsOne']: # éå†æ¯ä¸€ç§åˆ’åˆ†æ–¹å¼
            for div in [-0.5,0.5,1.5]: #éå†æ¯ä¸€ä¸ªåˆ’åˆ†ç‚¹
                #è®¡ç®—eï¼Œå’ŒGx
                tmp_Gx,tmp_e=cal_Gx_e(X,Y,div,rule,D,i)
                if tmp_e<single_boosting_tree['e']: #è·å¾—äº†æ›´å¥½çš„åˆ’åˆ†æ–¹å¼,ä¿å­˜
                    single_boosting_tree['e'] = tmp_e
                    single_boosting_tree['Gx'] = tmp_Gx
                    single_boosting_tree['div'] = div
                    single_boosting_tree['rule']=rule
                    single_boosting_tree['feature']=i

    single_boosting_tree['alpha']=1/2*np.log((1-single_boosting_tree['e'])/single_boosting_tree['e'])
    #è¿”å›å•å±‚æå‡æ ‘
    return single_boosting_tree

def create_boosting_tree(X,Y,tree_num=50):

    m,n=X.shape
    # åˆå§‹åŒ–æƒå€¼ï¼Œæ¯ä¸ªæ ·æœ¬çš„æƒå€¼æ˜¯1/m
    D=np.array([1/m]*m) # ä½¿ç”¨np.arrayä¾¿äºè®¡ç®—

    Fx=[0]*m #ç”¨äºè®¡ç®—å½“å‰åˆ†ç±»å™¨çš„è¾“å‡º å¯¹åº”ä¸å…¬å¼8.6

    boosting_tree=[]
    for i in range(tree_num): #å¼€å§‹æ„é€ æå‡æ ‘
        single_boosting_tree=create_single_boosting_tree(X,Y,D)
        #æ ¹æ®ä¸Šä¸€æ¬¡æ„é€ çš„å•å±‚æå‡æ ‘æ¥æ›´æ–°è¯¯åˆ†ç±»æ ·æœ¬çš„æƒé‡
        # éœ€è¦ç†Ÿæ‚‰np.arrayçš„è¿ç®—
        # ä¸¾ä¸ªğŸŒ°
        # a = np.array([1, 2, 3, 4])
        # b = np.array([1, 2, 3, 4])
        #
        # print(a * b)   è¾“å‡º[ 1  4  9 16]
        # print(np.sum(a * b))  è¾“å‡º 30

        # è®¡ç®—è§„èŒƒåŒ–å› å­ï¼Œå¯¹åº”äºå…¬å¼8.5
        Zm=np.sum(D*np.exp(-1*single_boosting_tree['alpha']*Y*single_boosting_tree['Gx']))
        # è®¡ç®—ä¸‹ä¸€è½®D
        D=D/Zm*np.exp(-1*single_boosting_tree['alpha']*Y*single_boosting_tree['Gx'])

        boosting_tree.append(single_boosting_tree)


        # å½“å‰çº¿æ€§é¢„æµ‹å€¼,å¯¹åº”å…¬å¼8,6
        Fx+=single_boosting_tree['alpha']+single_boosting_tree['Gx']

        # æœ€ç»ˆåˆ†ç±»èµ·é¢„æµ‹å€¼ å…¬å¼8.7
        Gx=np.sign(Fx)
        # æ€»çš„é”™è¯¯ä¸ªæ•°
        total_error_num=np.sum([1 for i in range(m) if Gx[i]!=Y[i]])
        # è¯¯å·®ç‡
        total_error_rate=total_error_num/m

        #æ²¡æœ‰è¯¯å·®äº†ï¼Œå°±å¯ä»¥ç›´æ¥è¿”å›
        if total_error_rate==0:
            return boosting_tree

        print(f'in {i}th epoch, error={single_boosting_tree["e"]}. total error is {total_error_rate}')

    return boosting_tree


def predict(x,tree):
    '''
    ç”¨äºé¢„æµ‹ä¸€ä¸ªæ ·æœ¬çš„è¾“å‡º
    :param x:
    :param tree: æå‡æ ‘
    :return: GXï¼Œé¢„æµ‹å€¼
    '''
    fx = 0  # åˆ†ç±»å™¨çº¿æ€§ç´¯åŠ å€¼

    for i in range(len(tree)):
        div=tree[i]['div']
        rule=tree[i]['rule']
        alpha=tree[i]['alpha']
        feature=tree[i]['feature']



        # è¿™é‡Œæ³¨æ„ï¼Œæ¯ä¸€ä¸ªæ¯ç±»å™¨æœ€ç»ˆé¢„æµ‹çš„Gmxæ˜¯+1ï¼Œ-1ã€‚
        # fx=sumï¼ˆalpha*Gmxï¼‰
        # Gx=signï¼ˆfxï¼‰
        if rule=='LessIsOne':
            # åœ¨LessIsOneè§„åˆ™ä¸‹ï¼Œå°äºdivé¢„æµ‹ä¸º1ï¼Œå¤§äºé¢„æµ‹ä¸º-1
            if x[feature]<div:
                fx+=alpha*1
            else:
                fx+=alpha*(-1)
        else: #BiggerIsOne
            if x[feature]<div:
                fx+=alpha*(-1)
            else:
                fx+=alpha*1

    Gx=np.sign(fx)
    return Gx

def test(X,Y,tree):
    acc = 0  # æ­£ç¡®ç‡
    acc_num = 0  # æ­£ç¡®ä¸ªæ•°
    for i in range(len(X)):
        print('testing ***', i)
        Gx=predict(X[i],tree)
        if Gx == Y[i]:
            acc_num += 1
        print(f'testing {i}th data :y_pred={Gx},y={Y[i]}')
        print('now_acc=', acc_num / (i + 1))



if __name__=='__main__':

    # è·å–å½“å‰æ—¶é—´
    start = time.time()

    # è¯»å–è®­ç»ƒæ–‡ä»¶
    print('load TrainData')
    X_train, y_train = loadData('../Mnist/mnist_train.csv')

    # è¯»å–æµ‹è¯•æ–‡ä»¶
    print('load TestData')
    X_test, y_test = loadData('../Mnist/mnist_test.csv')

    boosting_tree=create_boosting_tree(X_train[0:1000],y_train[0:1000],30)

    test(X_test[0:200],y_test[0:200],boosting_tree)

    end=time.time()

    print(end-start)



    # # é¸¢å°¾èŠ±æ•°æ®é›† 100%
    # from sklearn import datasets
    # from sklearn.model_selection import train_test_split
    #
    # iris = datasets.load_iris()
    # X = iris.data
    # y = iris.target
    #
    # X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=3)
    # y_train[y_train>0]=1
    # y_train[y_train==0]=-1
    # y_test[y_test > 0] = 1
    # y_test[y_test == 0] = -1
    #
    # boosting_tree=create_boosting_tree(X_train,y_train,10)
    # test(X_test,y_test,boosting_tree)







































